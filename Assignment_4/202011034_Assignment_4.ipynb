{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"202011034_Assignment_4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMXOFJt0HFuTrxF8g/F86Gw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AtOGEIq1LFRK"},"source":["# PRML Assignment 4\r\n","\r\n","@uthor: Darshil Patel(202011034)"]},{"cell_type":"code","metadata":{"id":"TFWU73FXK5LO","executionInfo":{"status":"ok","timestamp":1615646985281,"user_tz":-330,"elapsed":1185,"user":{"displayName":"2020 11034","photoUrl":"","userId":"11154967412412261153"}}},"source":["#useful librarys for this assigment\r\n","import numpy as np\r\n","import pandas as pd\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn import preprocessing"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Kcnl2wMM6xd","executionInfo":{"status":"ok","timestamp":1615646990479,"user_tz":-330,"elapsed":1202,"user":{"displayName":"2020 11034","photoUrl":"","userId":"11154967412412261153"}}},"source":["def load_iris_data():\r\n","  data = pd.read_csv(filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None,sep=',')\r\n","  data.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'flower_class']\r\n","  data.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\r\n","  return data\r\n","\r\n","# data split function\r\n","def my_train_test_split(data_frame,test_size):\r\n","  grouped = data_frame.groupby(data_frame.flower_class)\r\n","  setosa = grouped.get_group(0)\r\n","  versicolor = grouped.get_group(1)\r\n","  virginica = grouped.get_group(2)\r\n","\r\n","  # fetures and labels\r\n","  x_setosa = setosa.iloc[:,:-1]\r\n","  y_setosa = setosa.iloc[:,-1]\r\n","  x_versicolor = versicolor.iloc[:,:-1]\r\n","  y_versicolor = versicolor.iloc[:,-1]\r\n","  x_virginica = virginica.iloc[:,:-1]\r\n","  y_virginica = virginica.iloc[:,-1]\r\n","\r\n","  # randomely spliting\r\n","  x_train_setosa, x_test_setosa, y_train_setosa, y_test_setosa  = train_test_split(x_setosa, y_setosa,test_size=test_size)\r\n","  x_train_versicolor, x_test_versicolor, y_train_versicolor, y_test_versicolor= train_test_split(x_versicolor, y_versicolor, test_size=test_size)\r\n","  x_train_virginica, x_test_virginica,  y_train_virginica, y_test_virginica,= train_test_split(x_virginica, y_virginica, test_size=test_size)\r\n","\r\n","  # train data and label\r\n","  x_train = pd.concat([x_train_setosa , x_train_versicolor, x_train_virginica])\r\n","  y_train = list(pd.concat([y_train_setosa, y_train_versicolor, y_train_virginica]))\r\n","  \r\n","  # test data and label\r\n","  x_test = pd.concat([x_test_setosa , x_test_versicolor, x_test_virginica])\r\n","  y_test = list(pd.concat([y_test_setosa, y_test_versicolor, y_test_virginica]))\r\n","\r\n","  return x_train,x_test,y_train,y_test\r\n","\r\n","# get accuracy from test label and predicted label\r\n","def accuracy(y_test,y_predict):\r\n","  error = 0\r\n","  for x,y in zip(y_test,y_predict):\r\n","    if x != y:\r\n","      error += 1\r\n","  ac = ((len(y_test)-error)/len(y_test))*100\r\n","  return ac"],"execution_count":122,"outputs":[]},{"cell_type":"code","metadata":{"id":"3WzMEaClPNYW","executionInfo":{"status":"ok","timestamp":1615646998977,"user_tz":-330,"elapsed":1256,"user":{"displayName":"2020 11034","photoUrl":"","userId":"11154967412412261153"}}},"source":["# Naive Bayes classifer class\r\n","class NaiveBayes():\r\n","  # initialized parameters\r\n","  def __init__(self):\r\n","    self.parameters = dict()\r\n","    self.class_probability = dict()\r\n","\r\n","  # fit method to train data\r\n","  def fit(self,data,label):\r\n","\r\n","    # total number of data\r\n","    n = len(data)\r\n","\r\n","    # seperate data by class labels\r\n","    seperated_data = dict()\r\n","    for i in range(n):\r\n","      sample = data[i]\r\n","      class_label = label[i]\r\n","      if (class_label not in seperated_data):\r\n","        seperated_data[class_label] = list()\r\n","      seperated_data[class_label].append(sample)\r\n","\r\n","    # calculate mean and standard deviation of each feature of each class\r\n","    self.class_probability = dict()\r\n","    self.parameters = dict()\r\n","    for class_label,samples in seperated_data.items():\r\n","      self.class_probability[class_label] = len(samples)/n\r\n","      self.parameters[class_label] = [[np.mean(column), np.std(column)] for column in zip(*samples)]\r\n","\r\n","  # probability of sample for considering class as gaussian distribution \r\n","  def P(self,x,mean,stdev):\r\n","    exponent = np.exp(-((x-mean)**2 / (2 * stdev**2 )))\r\n","    return (1 / (np.sqrt(2 * np.pi) * stdev)) * exponent\r\n","\r\n","  # P(x/y) where x is sample and y is class(label) \r\n","  def P_of_x_given_y(self,x,y):\r\n","    ans = 1\r\n","    for value,par in zip(x,self.parameters[y]):\r\n","      ans = ans*self.P(value,par[0],par[1])\r\n","    return ans\r\n","    \r\n","  # P(x) where x is sampe \r\n","  def P_of_x(self,x):\r\n","    ans = 0\r\n","    for class_label in self.class_probability:\r\n","      ans += self.P_of_x_given_y(x,class_label)*self.class_probability[class_label]\r\n","    return ans\r\n","\r\n","  # P(Y/X) where x is sample and y is class(label) \r\n","  def P_of_y_given_x(self,y,x):\r\n","    return (self.P_of_x_given_y(x,y)*self.class_probability[y])/self.P_of_x(x)\r\n","  \r\n","  # predect the labels of test data \r\n","  def predict(self,data):\r\n","    y_predict = []\r\n","    for i in range(len(data)):\r\n","      classwise_probability = dict()\r\n","      predicted_class = None\r\n","      predicted_class_probability = -1\r\n","\r\n","      # calculate class wise probability \r\n","      for class_label in self.class_probability:\r\n","        classwise_probability[class_label] = self.P_of_y_given_x(class_label,data[i])\r\n","        \r\n","        # select class with maximum probability\r\n","        if classwise_probability[class_label] >= predicted_class_probability:\r\n","          predicted_class = class_label\r\n","          predicted_class_probability = classwise_probability[class_label]\r\n","\r\n","      # predict labels\r\n","      y_predict.append(predicted_class)\r\n","    return y_predict\r\n","\r\n","    "],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"MrMJe8iSNYvE","executionInfo":{"status":"ok","timestamp":1615647004740,"user_tz":-330,"elapsed":1664,"user":{"displayName":"2020 11034","photoUrl":"","userId":"11154967412412261153"}},"outputId":"5551ec9e-ce08-407d-ecee-4ae4e1fc7965"},"source":["# load data\r\n","data = load_iris_data()\r\n","\r\n","# encode labels \r\n","label_encoder = preprocessing.LabelEncoder()\r\n","data['flower_class']= label_encoder.fit_transform(data['flower_class'])\r\n","data.head()"],"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal_len</th>\n","      <th>sepal_wid</th>\n","      <th>petal_len</th>\n","      <th>petal_wid</th>\n","      <th>flower_class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal_len  sepal_wid  petal_len  petal_wid  flower_class\n","0        5.1        3.5        1.4        0.2             0\n","1        4.9        3.0        1.4        0.2             0\n","2        4.7        3.2        1.3        0.2             0\n","3        4.6        3.1        1.5        0.2             0\n","4        5.0        3.6        1.4        0.2             0"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4fYmHxGNgcH","executionInfo":{"status":"ok","timestamp":1615647013378,"user_tz":-330,"elapsed":1195,"user":{"displayName":"2020 11034","photoUrl":"","userId":"11154967412412261153"}},"outputId":"6984940e-e00d-4d7b-d729-5d149772eba3"},"source":["sum_ac = 0\r\n","for _ in range(10):\r\n","  print(\"-------------------------Iteration\",_+1,\"-------------------------\")\r\n","  # split dataset \r\n","  x_train,x_test,y_train,y_test = my_train_test_split(data,test_size=0.2)\r\n","\r\n","  # convert to numpy metrix\r\n","  x_train = x_train.to_numpy()\r\n","  x_test = x_test.to_numpy()\r\n","\r\n","  # create model\r\n","  naive_bayes = NaiveBayes()\r\n","\r\n","  # train model\r\n","  naive_bayes.fit(x_train,y_train)\r\n","\r\n","  # test model\r\n","  y_predict = naive_bayes.predict(x_test)\r\n","\r\n","  # model's accuracy\r\n","  ac = accuracy(y_test,y_predict)\r\n","  print(\"original classes:-\\n\",list(y_test))\r\n","  print(\"predicted classes:-\\n\",y_predict)\r\n","  print(\"accuracy :-\",ac,'%')\r\n","  sum_ac += ac\r\n","\r\n","print('--------------------------------')\r\n","\r\n","# model's average accuracy \r\n","ans = sum_ac/10\r\n","print(\"model's accuracy :-\",ans)"],"execution_count":125,"outputs":[{"output_type":"stream","text":["-------------------------Iteration 1 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","accuracy :- 96.66666666666667 %\n","-------------------------Iteration 2 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2]\n","accuracy :- 96.66666666666667 %\n","-------------------------Iteration 3 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","accuracy :- 93.33333333333333 %\n","-------------------------Iteration 4 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","accuracy :- 100.0 %\n","-------------------------Iteration 5 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2]\n","accuracy :- 96.66666666666667 %\n","-------------------------Iteration 6 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2]\n","accuracy :- 96.66666666666667 %\n","-------------------------Iteration 7 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2]\n","accuracy :- 93.33333333333333 %\n","-------------------------Iteration 8 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","accuracy :- 96.66666666666667 %\n","-------------------------Iteration 9 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","accuracy :- 100.0 %\n","-------------------------Iteration 10 -------------------------\n","original classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","predicted classes:-\n"," [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","accuracy :- 100.0 %\n","--------------------------------\n","model's accuracy :- 97.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xf-kBs4zuSd9","executionInfo":{"status":"ok","timestamp":1615647033563,"user_tz":-330,"elapsed":1242,"user":{"displayName":"2020 11034","photoUrl":"","userId":"11154967412412261153"}},"outputId":"d1f540f9-59a3-4bb4-a8c4-645325652807"},"source":["# implement using sklearn module\r\n","\r\n","from sklearn.naive_bayes import GaussianNB\r\n","from sklearn.metrics import accuracy_score\r\n","\r\n","x_train,x_test,y_train,y_test = my_train_test_split(data,test_size=0.2)\r\n","classifier = GaussianNB()\r\n","classifier.fit(x_train, y_train)\r\n","y_pred = classifier.predict(x_test)\r\n","\r\n","print (\"Accuracy : \", accuracy_score(y_test, y_pred)*100)"],"execution_count":130,"outputs":[{"output_type":"stream","text":["Accuracy :  96.66666666666667\n"],"name":"stdout"}]}]}